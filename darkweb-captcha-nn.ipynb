{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed length CAPTCHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FixedLengthCRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FixedLengthCRNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3))\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=(3, 3))\n",
    "\n",
    "        # Assuming the input size is fixed and known, calculate the size here\n",
    "        # For example, let's assume the output of the last conv layer is (batch_size, 64, H, W)\n",
    "        # You will need to adjust H and W based on your actual output sizes\n",
    "        self.rnn_input_size = 64  # This needs to be adjusted based on the output shape after conv layers\n",
    "        self.rnn_hidden_size = 128\n",
    "\n",
    "        self.lstm = nn.LSTM(self.rnn_input_size, self.rnn_hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # For a fixed length of 4 and 36 possible characters, adjust the linear layer\n",
    "        self.fc = nn.Linear(self.rnn_hidden_size * 2, 4 * 36)  # 128 * 2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        # Adjust dimensions before feeding into RNN\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.permute(0, 3, 1, 2)  # Change to (batch, width, channels, height)\n",
    "        x = x.view(batch_size, width, -1)  # Flatten the channels and height into a single dimension\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # Reshape to (batch_size, 4, 36) to get predictions for each of the 4 characters\n",
    "        x = x.view(batch_size, 4, 36)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Note: You may need to adjust self.rnn_input_size and the reshaping in forward() based on the actual output size after the conv layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable length CAPTCHA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Overview\n",
    "\n",
    "#### Input Layer\n",
    "- **Size**: Match preprocessed CAPTCHA images, e.g., `(60, 160, 1)` for height, width, and channels (for grayscale images).\n",
    "\n",
    "#### Convolutional Layers\n",
    "- **Purpose**: Extract features. Increase depth while reducing spatial dimensions through pooling.\n",
    "- **Configuration**: Several convolutional layers, each followed by max pooling layers.\n",
    "\n",
    "#### Recurrent Layer\n",
    "- **Type**: RNN with LSTM or GRU units.\n",
    "- **Purpose**: Process features in sequence, crucial for recognizing characters in CAPTCHA.\n",
    "\n",
    "#### Dense Layer with Softmax\n",
    "- **Function**: Multi-class classification for each character position in the CAPTCHA.\n",
    "- **Activation**: Softmax, to output probabilities for each possible character.\n",
    "\n",
    "#### Connectionist Temporal Classification (CTC) Loss\n",
    "- **Purpose**: Handle variable length of CAPTCHA strings and alignment between inputs and targets.\n",
    "\n",
    "### Rationale\n",
    "- **CNN + RNN**: CNNs are excellent for spatial feature extraction, RNNs understand sequence dynamics. This combo is effective for spatial and sequential recognition tasks like CAPTCHA.\n",
    "- **CTC Loss**: Ideal for sequence recognition with variable lengths and unknown alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model architecture\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), activation='relu')\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), activation='relu')\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=(3, 3), activation='relu')\n",
    "        self.rnn_input_size = 64 * 15 * 40  # Update according to the output shape after conv layers\n",
    "        self.lstm = nn.LSTM(self.rnn_input_size, 128, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 11)  # 128 * 2 for bidirectional, 10 + 1 for classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Custom CTC Loss\n",
    "# In PyTorch, CTC Loss is already implemented and can be used directly.\n",
    "# You will need to provide logits from your model, target (labels), input_lengths, and target_lengths\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "# Example on how to calculate CTC Loss\n",
    "# logits: tensor of shape (T, N, C) where T is the maximum sequence length, N is the batch size, C is the number of classes (including blank)\n",
    "# labels: tensor of shape (sum(target_lengths))\n",
    "# input_lengths: tensor of size (N)\n",
    "# target_lengths: tensor of size (N)\n",
    "# loss = ctc_loss(logits, labels, input_lengths, target_lengths)\n",
    "\n",
    "# Note: Make sure to use log_softmax on your output logits before passing them to CTC loss\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
